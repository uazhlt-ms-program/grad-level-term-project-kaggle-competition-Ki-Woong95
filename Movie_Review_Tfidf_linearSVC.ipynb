{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1eb1f24-4ebf-49dd-9c21-d636a11e2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import settings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8464bec0-83ad-4145-87e4-4e8793dbc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2b74de-e484-4562-9fa3-24338b6aeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv(path+'/data/train.csv')\n",
    "\n",
    "# Replace NA values in TEXT into \"blank\"\n",
    "X = train_df['TEXT'].fillna(\"blank\").astype(str)\n",
    "y = train_df['LABEL']\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2705e203-8e97-4fde-9b63-abf6cbf272fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average text length per label:\n",
      "LABEL\n",
      "0.0     468.774793\n",
      "1.0    1191.318158\n",
      "2.0    1176.716088\n",
      "Name: TEXT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add 'LABEL' column to the DataFrame\n",
    "train_df['LABEL'] = y_train\n",
    "\n",
    "# Calculate average text length for each label\n",
    "avg_length_per_label = train_df.groupby('LABEL')['TEXT'].apply(lambda x: x.str.len().mean())\n",
    "\n",
    "# Print the average length for each label\n",
    "print(\"Average text length per label:\")\n",
    "print(avg_length_per_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5132c74-6580-436f-8b51-771dcd28a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizers\n",
    "#TfidfVectorizer: ngram_range : upto trigram, lowercase\n",
    "#CountVectorizer was also tested, but due to low performance, it was removed\n",
    "tfidf_vect = TfidfVectorizer(ngram_range= (1,3),lowercase = True)\n",
    "\n",
    "# Fit and transform the train data\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vect.transform(X_val)\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit LabelEncoder on the labels\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "\n",
    "# Transform labels to numeric values\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de0ef4a-fe8e-480a-a63c-a2682a9667fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a class called Classifiers:\n",
    "\n",
    "Three machine learning algorithms will be tested\n",
    "    1. Logistic regression\n",
    "    2. Multinomial naive_bayes model\n",
    "    3. Liner Support vector classifier\n",
    "\n",
    "'''\n",
    "\n",
    "class Classifiers:\n",
    "    def __init__(self):\n",
    "        self.logistic = LogisticRegression(max_iter = 1000, C = 3)\n",
    "        self.bayes = MultinomialNB()\n",
    "        self.svm = LinearSVC(max_iter = 1000, C = 3)\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        self.logistic.fit(features,labels)\n",
    "        self.bayes.fit(features,labels)\n",
    "        self.svm.fit(features,labels)\n",
    "\n",
    "\n",
    "    def predict(self, features):\n",
    "        return self.logistic.predict(features), self.bayes.predict(features), self.svm.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2edf75-32df-4dab-ad75-f1fbcc5a7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize classifier\n",
    "clf = Classifiers()\n",
    "\n",
    "#Fit the vectorizer into the models\n",
    "clf.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "#Predictions\n",
    "logistics, bayes,svm = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838c5667-7c8f-4e51-aa00-dd019a4ff8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressions: ==================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Not a movie       0.97      0.97      0.97      6454\n",
      "Positive review       0.87      0.90      0.88      3856\n",
      "Negative review       0.91      0.88      0.89      3754\n",
      "\n",
      "       accuracy                           0.93     14064\n",
      "      macro avg       0.92      0.91      0.91     14064\n",
      "   weighted avg       0.93      0.93      0.93     14064\n",
      "\n",
      "Naive Bayes Model: ==================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Not a movie       0.97      0.94      0.96      6454\n",
      "Positive review       0.86      0.85      0.85      3856\n",
      "Negative review       0.85      0.91      0.88      3754\n",
      "\n",
      "       accuracy                           0.91     14064\n",
      "      macro avg       0.89      0.90      0.90     14064\n",
      "   weighted avg       0.91      0.91      0.91     14064\n",
      "\n",
      "Linear SVC: ==================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Not a movie       0.98      0.98      0.98      6454\n",
      "Positive review       0.88      0.90      0.89      3856\n",
      "Negative review       0.92      0.89      0.90      3754\n",
      "\n",
      "       accuracy                           0.93     14064\n",
      "      macro avg       0.92      0.92      0.92     14064\n",
      "   weighted avg       0.93      0.93      0.93     14064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print each algorithm's classification report\n",
    "\n",
    "print(\"Logistic Regressions:\", '=' * 50)\n",
    "print(classification_report(y_val, logistics, target_names = ['Not a movie', \"Positive review\", \"Negative review\"]))\n",
    "\n",
    "print(\"Naive Bayes Model:\", '=' * 50)\n",
    "print(classification_report(y_val, bayes, target_names = ['Not a movie', \"Positive review\", \"Negative review\"]))\n",
    "\n",
    "print(\"Linear SVC:\", '=' * 50)\n",
    "print(classification_report(y_val, svm, target_names = ['Not a movie', \"Positive review\", \"Negative review\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e0ef52-3d8a-489b-9cf5-57be6e59b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test datset\n",
    "test_df = pd.read_csv(path + '/data/test.csv')\n",
    "\n",
    "#Fill NA values in TEXT to \"blank\"\n",
    "test_df = test_df.fillna('blank')\n",
    "\n",
    "#Transform the TEXT into tfidf vectorizer\n",
    "test_tfidf = tfidf_vect.transform(test_df['TEXT'])\n",
    "\n",
    "#Prediction based on the best performing model (LinearSVC)\n",
    "_,_,predictions = clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e34b90-2bac-42b2-a077-d75e9b9d15fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4728459160322025755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1840432070229003467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623336783082722606</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7446733850828603409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16180660281866613068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  LABEL\n",
       "0   4728459160322025755      1\n",
       "1   1840432070229003467      1\n",
       "2  12623336783082722606      2\n",
       "3   7446733850828603409      0\n",
       "4  16180660281866613068      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a data frame for the submission of the prediction columns: ID, LABEL\n",
    "submission = pd.DataFrame(columns=['ID','LABEL'])\n",
    "submission['ID'] = test_df['ID']\n",
    "submission['LABEL'] = predictions\n",
    "\n",
    "#Check the dataframe\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c541b3d1-1aa7-4970-986d-5a5d9fe43f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as a .csv file\n",
    "submission.to_csv(path + '/submission_v6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f94af-f98f-46f7-a081-b43b19276f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
