{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2733dcb5-6fd1-4517-93e0-c398398df5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import settings\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b693e9-592e-411a-82bf-72e220f9bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train dataset\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train = train.fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14986d5b-afce-41c9-9b68-e270855b598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7850790573542594519</td>\n",
       "      <td>If you love good films don't ever buy this pei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9392069522632994700</td>\n",
       "      <td>The 33 percent of the nations nitwits that sti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5083704536542443514</td>\n",
       "      <td>I saw Anatomy years ago -- dubbed at a friends...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12418349755186772171</td>\n",
       "      <td>Dark Remains is a home run plain and simple. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12144957944004619479</td>\n",
       "      <td>Feh. This movie started out in an interesting ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                               TEXT  \\\n",
       "0   7850790573542594519  If you love good films don't ever buy this pei...   \n",
       "1   9392069522632994700  The 33 percent of the nations nitwits that sti...   \n",
       "2   5083704536542443514  I saw Anatomy years ago -- dubbed at a friends...   \n",
       "3  12418349755186772171  Dark Remains is a home run plain and simple. T...   \n",
       "4  12144957944004619479  Feh. This movie started out in an interesting ...   \n",
       "\n",
       "  LABEL  \n",
       "0     2  \n",
       "1     2  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b7a086-dfa6-449c-9f5e-b0ea1a0794cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41e5ce7f5f845049c8a3cee72352ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize pre_trained sentiment analyzer \"VADER\"\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "#Store sentiment values (positive, negative, neutral, compound score which gives the direction of sentiment in the texts)\n",
    "res = {}\n",
    "for i , row in tqdm(train.iterrows(), total = len(train)):\n",
    "    text = row['TEXT']\n",
    "    myid = row['ID']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be20c935-971a-439e-8d27-47d60957df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge sentiment values with the train data\n",
    "\n",
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'ID'})\n",
    "train_df = vaders.merge(train, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67974a9-07d5-40dd-8eb4-09fe15ae546d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7850790573542594519</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>If you love good films don't ever buy this pei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9392069522632994700</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.9680</td>\n",
       "      <td>The 33 percent of the nations nitwits that sti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5083704536542443514</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>I saw Anatomy years ago -- dubbed at a friends...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12418349755186772171</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.5815</td>\n",
       "      <td>Dark Remains is a home run plain and simple. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12144957944004619479</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.9981</td>\n",
       "      <td>Feh. This movie started out in an interesting ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID    neg    neu    pos  compound  \\\n",
       "0   7850790573542594519  0.137  0.474  0.389    0.6996   \n",
       "1   9392069522632994700  0.193  0.699  0.108   -0.9680   \n",
       "2   5083704536542443514  0.105  0.760  0.136    0.3469   \n",
       "3  12418349755186772171  0.131  0.777  0.092   -0.5815   \n",
       "4  12144957944004619479  0.265  0.633  0.102   -0.9981   \n",
       "\n",
       "                                                TEXT LABEL  \n",
       "0  If you love good films don't ever buy this pei...     2  \n",
       "1  The 33 percent of the nations nitwits that sti...     2  \n",
       "2  I saw Anatomy years ago -- dubbed at a friends...     1  \n",
       "3  Dark Remains is a home run plain and simple. T...     1  \n",
       "4  Feh. This movie started out in an interesting ...     2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the outcome of the merged dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deaf68f3-ac87-4089-aadc-4c37a9d4764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average values by Label:\n",
      "            neg       neu       pos  compound\n",
      "LABEL                                        \n",
      "0      0.041618  0.721098  0.236781  0.503356\n",
      "1      0.064054  0.757730  0.178214  0.675200\n",
      "2      0.121956  0.766397  0.111646 -0.083287\n"
     ]
    }
   ],
   "source": [
    "#Checking the avearage values of each sentiment categories (including compound score)\n",
    "\n",
    "average_values = train_df.groupby('LABEL')[['neg', 'neu', 'pos', 'compound']].mean()\n",
    "print(\"Average values by Label:\")\n",
    "print(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a9fcaa-66b1-4e5e-ba1b-f82b66e789a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      6454\n",
      "           1       0.90      0.89      0.90      3856\n",
      "           2       0.91      0.90      0.90      3754\n",
      "\n",
      "    accuracy                           0.94     14064\n",
      "   macro avg       0.93      0.92      0.93     14064\n",
      "weighted avg       0.94      0.94      0.94     14064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign text, compound and labels for splitting the data\n",
    "X_text = train_df['TEXT']  # Text of the data\n",
    "X_compound = train_df[['compound', 'neg', 'pos']]  # Add 'compound', 'neg', 'pos' scores as a feature\n",
    "y = train_df['LABEL']\n",
    "\n",
    "# Splitting the Data (Validation_size: 20%, Train_size = 80%)\n",
    "X_train_text, X_test_text, X_train_compound, X_test_compound, y_train, y_test = train_test_split(\n",
    "    X_text, X_compound, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Concatenate text and compound score data\n",
    "X_train_combined = pd.concat([X_train_text, X_train_compound], axis=1)\n",
    "X_test_combined = pd.concat([X_test_text, X_test_compound], axis=1)\n",
    "\n",
    "'''\n",
    "Pipeline for Vectorization and Model Training:\n",
    "    vectorizer = TfidfVectorizer (N-gram = (1,3), min_df = 5, max_df = 0.4) ignore terms that appear less than 5, \n",
    "                                  and ignore terms that appear more than 40% of the document)\n",
    "    compound_preprocessor = adjusting sentiment scores having a mean of 0 and a standard devieation of 1\n",
    "'''\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,3), min_df = 5, max_df = 0.4)\n",
    "compound_preprocessor = StandardScaler()\n",
    "\n",
    "\n",
    "# Use sklearn.compose.Columntransformer to apply vectorization of terms and scaling of compound scores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', vectorizer, 'TEXT'),\n",
    "        ('compound', compound_preprocessor, ['compound', 'neg', 'pos'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build classifier\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        # Preprocess the data with vectorization of terms & scaling of compound score\n",
    "        ('preprocessor', preprocessor),\n",
    "        # Logistic Regression classifier\n",
    "        ('classifier', LogisticRegression(max_iter = 1000, \n",
    "                                          C = 50, \n",
    "                                          solver = 'saga', \n",
    "                                          multi_class = 'multinomial',\n",
    "                                          class_weight = 'balanced',\n",
    "                                         ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Prediction with the validation set\n",
    "y_pred = model.predict(X_test_combined)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9e2c3c-2319-4bc2-af54-a8c8d8f6f333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9264813555279808\n"
     ]
    }
   ],
   "source": [
    "# Print macro F1-Score\n",
    "f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d75be9e-51c3-470b-ba90-6ff73a897a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Fill NA values in TEXT to \"\"\n",
    "test = test.fillna('').astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8cb4853-6cd3-4092-b0e5-5da2725d0370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd654295b8c4f5da1955718bfdba537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use VADER for calculating compound score in the test data\n",
    "res_test = {}\n",
    "for i , row in tqdm(test.iterrows(), total = len(test)):\n",
    "    text = row['TEXT']\n",
    "    myid = row['ID']\n",
    "    res_test[myid] = sia.polarity_scores(text)\n",
    "\n",
    "\n",
    "#Merge sentiment values with the test data\n",
    "\n",
    "test_vader = pd.DataFrame(res_test).T\n",
    "test_vader = test_vader.reset_index().rename(columns={'index': 'ID'})\n",
    "test_df = test_vader.merge(test, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32df739a-c589-402c-9615-09b9b493d087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4728459160322025755</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>An excellent debut movie for the the director ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1840432070229003467</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>If you have a preschooler or remember how stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623336783082722606</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-0.9740</td>\n",
       "      <td>What should have been a routine babysitting gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7446733850828603409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>Cute but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16180660281866613068</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.8659</td>\n",
       "      <td>Elvis Presley plays a \"half-breed\" Native Amer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID    neg    neu    pos  compound  \\\n",
       "0   4728459160322025755  0.038  0.856  0.106    0.8439   \n",
       "1   1840432070229003467  0.017  0.900  0.083    0.9768   \n",
       "2  12623336783082722606  0.151  0.737  0.111   -0.9740   \n",
       "3   7446733850828603409  0.000  0.333  0.667    0.2500   \n",
       "4  16180660281866613068  0.064  0.826  0.110    0.8659   \n",
       "\n",
       "                                                TEXT  \n",
       "0  An excellent debut movie for the the director ...  \n",
       "1  If you have a preschooler or remember how stre...  \n",
       "2  What should have been a routine babysitting gi...  \n",
       "3                                           Cute but  \n",
       "4  Elvis Presley plays a \"half-breed\" Native Amer...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the outcome of the merged data frame\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a65e99dd-36f7-4287-a7b9-5dfd37f6c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the 'TEXT' column from df_test with the 'compound', 'neg', and 'pos' scores and extract features\n",
    "X_test = test_df[['TEXT', 'compound', 'neg', 'pos']] \n",
    "\n",
    "# Make predictions using the pipeline\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f252cd2-cdc2-4b63-9b7d-d3cfb8adada3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4728459160322025755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1840432070229003467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623336783082722606</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7446733850828603409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16180660281866613068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID LABEL\n",
       "0   4728459160322025755     1\n",
       "1   1840432070229003467     1\n",
       "2  12623336783082722606     2\n",
       "3   7446733850828603409     0\n",
       "4  16180660281866613068     2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a data frame for the submission of the prediction columns: ID, LABEL\n",
    "submission = pd.DataFrame(columns=['ID','LABEL'])\n",
    "submission['ID'] = test_df['ID']\n",
    "submission['LABEL'] = predictions\n",
    "\n",
    "#Check the dataframe\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97413a70-870c-4128-8ae4-95125a4c8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as a .csv file\n",
    "submission.to_csv('submission_v10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96640ed-a9ce-4773-9757-36ddcc37da4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
